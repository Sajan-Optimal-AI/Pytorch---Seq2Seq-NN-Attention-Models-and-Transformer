{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch Projects 3 : Multi30k.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIRcMykSUMxJ"
      },
      "source": [
        "1.Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqlltXa4gEMm"
      },
      "source": [
        "# About the data:\n",
        "#\"The dataset we'll be using is the Multi30k dataset. This is a dataset with ~30,000 parallel English, German and French sentences, each with ~12 words per sentence\""
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLXFfyqFKCOX"
      },
      "source": [
        "# import the dependencies\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy.datasets import Multi30k                                  # Dataset \n",
        "from torchtext.legacy.data import Field, BucketIterator                         # For text preprocessing\n",
        "import spacy                                                                    # For tokenization\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lscew1KbU7-Q"
      },
      "source": [
        "2.Data Preprocessing using torchtext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DrwZ_bLX0Ef",
        "outputId": "fbc9be6f-ac0c-4804-eeae-73f99d2c8e68"
      },
      "source": [
        "!python -m spacy download de_core_news_sm"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (56.1.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (4.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i1RYU6VYjc9"
      },
      "source": [
        "import en_core_web_sm\n",
        "import de_core_news_sm"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uezyxM2AZUjh"
      },
      "source": [
        "spacy_german = spacy.load('de_core_news_sm')\n",
        "spacy_english = spacy.load('en_core_web_sm')\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPFsyoI8aeZk"
      },
      "source": [
        "# To Tokenizes English and german text from a string into a list of strings (tokens):\n",
        "def tokenize_de(text):\n",
        "  return [tok.text for tok in spacy_german.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "  return [tok.text for tok in spacy_english.tokenizer(text)]"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJtLUUgVeW-X"
      },
      "source": [
        "# To set Field for assigning parameters for Data Preprocessing:\n",
        "SRC = Field(tokenize = tokenize_de,                         # initialize token as <sos> i.e start of sentence\n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>',                                   # eos_token as <eos> i.e end of sentence\n",
        "            lower = True)                                          # Lower case\n",
        "\n",
        "TRG= Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2LnfHXzfxMU"
      },
      "source": [
        "# Data Split:\n",
        "train_data, validation_data, test_data = Multi30k.splits(exts=('.de','.en'),\n",
        "                                                         fields = (SRC,TRG))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYfAjkxVniwk",
        "outputId": "6c95659e-2ecd-4863-e00d-27d6c5472a15"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data.examples)}\")                          #length of train_data i.e src len or trg len\n",
        "print(f\"Number of validation examples: {len(validation_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 29000\n",
            "Number of validation examples: 1014\n",
            "Number of testing examples: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwI56LBCn7WQ",
        "outputId": "03180d89-c267-4993-aebe-38d19e38f9d0"
      },
      "source": [
        "print(vars(train_data.examples[1500]))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'src': ['eine', 'person', 'in', 'einer', 'warnweste', ',', 'die', 'einen', 'lkw', 'schiebt', '.'], 'trg': ['a', 'person', 'in', 'a', 'safety', 'vest', 'pushing', 'a', 'truck', '.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH3Ohsw0pHNy"
      },
      "source": [
        "# Buliding Vocabulary \n",
        "SRC.build_vocab(train_data, min_freq = 2)            # It is essential vocabulary must be build from training set  and not the validation/test set to avoid information leakage in to the model. \n",
        "TRG.build_vocab(train_data, min_freq = 2)           # Using the min_freq argument, only allow tokens that appear at least 2 times in training set"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iiz6c5ORp6hV",
        "outputId": "6df715b9-d79a-4c14-f8f6-efb48714d302"
      },
      "source": [
        "print(f\"Unique tokens in source (German) vocabulary: {len(SRC.vocab)}\")               # input_dim to encoder\n",
        "print(f\"Unique tokens in target (English) vocabulary: {len(TRG.vocab)}\")              # output_dim to decoder"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in source (German) vocabulary: 7855\n",
            "Unique tokens in target (English) vocabulary: 5893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpeIzWjzN7sC"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4XVIy6fNyJc"
      },
      "source": [
        "#BucketIterator :The final step of preparing the data is to create the iterators. These can be iterated on to return a batch of data which will have the PyTorch tensors containing a batch of numericalized src and trg sentences. \n",
        "#Numericalized is just a fancy way of saying they have been converted from a sequence of readable tokens to a sequence of corresponding indexes, using the vocabulary.\n",
        "BATCH_SIZE = 128\n",
        "train_iterator, valid_iterator , test_iterator = BucketIterator.splits((train_data,validation_data,test_data),batch_size = BATCH_SIZE, device = device,sort_within_batch=True,)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx9AYTkuU5ZV",
        "outputId": "59ea98f0-c101-4260-e0cd-49434a55d98d"
      },
      "source": [
        "len(train_iterator),len(valid_iterator),len(test_iterator)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(227, 8, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya2yvI8fXkyQ",
        "outputId": "cd1ff1da-14e9-4c41-c692-b612baaba3ca"
      },
      "source": [
        "type(train_iterator)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchtext.legacy.data.iterator.BucketIterator"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpK0vRVovgKq"
      },
      "source": [
        "3.Seq2Seq Model Building "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EltNFYAnnRnF"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_dim,emb_dim,hid_dim,n_layers,dropout):\n",
        "    super().__init__()\n",
        "    self.hid_dim = hid_dim                                                #define hidden state\n",
        "    self.n_layers = n_layers                                               \n",
        "\n",
        "    self.embedding = nn.Embedding(input_dim,emb_dim)                      # input_dim = len(src.Vocab)<<one hot representation : emb_dim = embedding_vector_features<< dense representation \n",
        "    self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout= dropout)               #LSTM layer : hid_dim is the dimensionality of the hidden and cell states.\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self,src):                                               # src is german sequence which has shape of (src len and batch_size) (src len is sequential length)\n",
        "    embedded = self.dropout(self.embedding(src))                      #embedd = (src len,batch_size,emb dim)\n",
        "    outputs,(hidden,cell) = self.rnn(embedded)                  #outputs = [src len, batch_size, hid_dim* n directions]#hidden = [n_layers * n directions, batch_size,hid_dim] #cell = [n_layers * n directions,batch_size,hid_dim]\n",
        "    \n",
        "    return hidden,cell\n",
        "#n the forward method, we pass  the source sentence, which is converted into dense vectors using the embedding layer, and then dropout is applied. \n",
        "#These embeddings are then passed into the RNN. As  whole sequence is passed to the RNN, it will automatically do the recurrent calculation of the hidden states over the whole sequence.\n",
        "#Notice that we do not pass an initial hidden or cell state to the RNN so that if no hidden/cell state is passed to the RNN, it will automatically create an initial hidden/cell state as a tensor of all zeros.\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self,output_dim,emb_dim,hid_dim,n_layers,dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    self.output_dim = output_dim                                                  #output_dim = len(trg.Vocab)<<one hot representation\n",
        "    self.hid_dim = hid_dim\n",
        "    self.n_layers = n_layers\n",
        "\n",
        "    self.embedding = nn.Embedding(output_dim,emb_dim)                             #emb_dim = embedding_vector_features<< dense representation \n",
        "\n",
        "    self.rnn = nn.LSTM(emb_dim,hid_dim,n_layers,dropout = dropout)\n",
        "\n",
        "    self.fc_out = nn.Linear(hid_dim, output_dim)                                  # fully connected Dense layer at the top for output\n",
        "                            \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,input,hidden,cell):\n",
        "\n",
        "    input = input.unsqueeze(0)                                                    # input = [Batch_size] #hidden = [n layers * n directions, Batch_size, hid_dim]  #cell = [n layers * n directions, Batch_size, hid_dim] # n directions =1\n",
        "\n",
        "    embedded = self.dropout(self.embedding(input))                               # embedding_shape = (1,batch_size,emb_dim) # seq len is always 1 at decoder\n",
        "    output, (hidden, cell) = self.rnn(embedded, (hidden,cell))      # output = [1,Batch_size, hid_dim * n directions] #hidden = [n layers * n directions, Batch_size, hid_dim] #cell = [n layers * n directions, Batch_size, hid_dim]\n",
        "                                                                    # shape of predictions: (Batch_size,output_dim)\n",
        "    prediction = self.fc_out(output.squeeze(0))\n",
        "\n",
        "    return prediction,hidden,cell\n",
        "\n",
        "#Within the forward method, we accept a batch of input tokens, previous hidden states and previous cell states. \n",
        "#As we are only decoding one token at a time, the input tokens will always have a sequence length of 1.\n",
        "# We unsqueeze the input tokens to add a sentence length dimension of 1. Then, similar to the encoder, we pass through an embedding layer and apply dropout. \n",
        "#This batch of embedded tokens is then passed into the RNN with the previous hidden and cell states.i.e context vector \n",
        "#This produces an output (hidden state from the top layer of the RNN), a new hidden state (one for each layer, stacked on top of each other) and a new cell state (also one per layer, stacked on top of each other). \n",
        "#We then pass the output (after getting rid of the sentence length dimension) through the linear layer to receive our prediction. We then return the prediction, the new hidden state and the new cell state.        \n",
        "       \n",
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self,encoder,decoder,device):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.device = device\n",
        "\n",
        "    assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "        \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "    assert encoder.n_layers == decoder.n_layers, \\\n",
        "        \"Encoder and decoder must have equal number of layers!\"\n",
        "  \n",
        "  def forward(self, src, trg, teacher_forcing_ratio = 0.5):                                  #src = [src len, batch size] #trg = [trg len, batch size]  #teacher_forcing_ratio is probability to use teacher forcing \n",
        "    batch_size = trg.shape[1]                  #returns batch_size                           #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "    trg_len = trg.shape[0]                     #returns sequential length\n",
        "    trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "    outputs = torch.zeros(trg_len,batch_size,trg_vocab_size).to(self.device)         #tensor to store decoder outputs\n",
        "\n",
        "    hidden,cell = self.encoder(src)                                             #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "\n",
        "    input=trg[0,:]                                                              #first input to the decoder is the <sos> tokens\n",
        "\n",
        "    for t in range(1, trg_len):\n",
        "      output, hidden, cell = self.decoder(input,hidden,cell)       #receive output tensor (predictions) and new hidden and cell states by insert input token embedding, previous hidden and previous cell states\n",
        "\n",
        "      outputs[t] = output                                      #place predictions in a tensor holding predictions for each token\n",
        "\n",
        "      teacher_force = random.random() < teacher_forcing_ratio  #decide if we are going to use teacher forcing or not\n",
        "\n",
        "      top1 = output.argmax(1)                                  #get the highest predicted token from our predictions\n",
        "\n",
        "      input = trg[t] if teacher_force else top1                #if teacher forcing, use actual next token as next input if not, use predicted token\n",
        "\n",
        "    return outputs\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2Z64FB7vpBB"
      },
      "source": [
        "4.Assigning  Parameters, loss function , optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q5MKEL-wLtc"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilKTsO1-aMNc",
        "outputId": "7d1163a8-4e61-47ac-fe82-37890d3c7030"
      },
      "source": [
        "#Initialize the weights :\n",
        "def init_weights(m):\n",
        "  for name, param in m.named_parameters():     \n",
        "    nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights)\n",
        "#initialize all weights from a uniform distribution between -0.08 and +0.08.\n",
        "# The init_weights function will be called on every module and sub-module within our model. For each module, loop through all of the parameters and sample them from a uniform distribution with nn.init.uniform_.\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(7855, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(5893, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=512, out_features=5893, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqd6R-WGcRRm",
        "outputId": "d91c5103-4422-433d-d21d-7d28686881f7"
      },
      "source": [
        "#function that will calculate the number of trainable parameters in the model.\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 13,899,013 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3EZiZ0RC8jR"
      },
      "source": [
        "#Defining Optimizer:to update our parameters in the training loop\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1SiBsrt_M05"
      },
      "source": [
        "#Defining loss function:\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "#oss function calculates the average loss per token, however by passing the index of the <pad> token as the ignore_index argument ignores the loss whenever the target token is a padding token."
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS9Ba9YiP6Gx"
      },
      "source": [
        "5.Define Training loop:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqat5jwvdq4L"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()                                                # Set the model into training mode\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src                                          #get the source and target sentences from the batch\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()                                    #zero the gradients calculated from the last batch\n",
        "        \n",
        "        output = model(src, trg)                                 #feed the source and target into the model to get the output,\n",
        "        \n",
        "        output_dim = output.shape[-1]                            ##trg = [trg len, batch size]  #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)                 #loss function only works on 2d inputs with 1d targets we need to flatten each of them with '.view'. we slice off the first column of the output and target tensors\n",
        "        trg = trg[1:].view(-1)\n",
        "                                                                 # #trg = [(trg len - 1) * batch size]  #output = [(trg len - 1) * batch size, output dim]\n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()                                          #calculate the gradients with loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)    #clip is used  to prevent gradients from exploding (a common issue in RNNs)\n",
        "        \n",
        "        optimizer.step()                                            #update the parameters of our model by doing an optimizer step\n",
        "        \n",
        "        epoch_loss += loss.item()                                   #sum the loss value to a running total\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-q6UJOlsCl4"
      },
      "source": [
        "6.Define Evaluation loop:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKJqyqu5r29x"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()                                                  #set the mode to evaluation. This will turn off dropout \n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():                                        #use the with torch.no_grad() block to ensure no gradients are calculated within the block. This reduces memory consumption and speeds things up \n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, trg, 0)                          # 0 indicates turn off teacher forcing  \n",
        "                                                                 #trg = [trg len, batch size] #output = [trg len, batch size, output dim]\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)                               #trg = [(trg len - 1) * batch size]  #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUTdpX8DwzIQ"
      },
      "source": [
        "#create a function that tell that how long an epoch takes.\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW4h3tOVxRFC"
      },
      "source": [
        "7.Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7P-EjSQxYJR",
        "outputId": "27305544-3aa2-4672-e750-7f90bfce5890"
      },
      "source": [
        "#At each epoch, we'll be checking if our model has achieved the best validation loss so far. If it has, we'll update our best validation loss and save the parameters of our model (called state_dict in PyTorch).\n",
        "#Then, when we come to test our model, we'll use the saved parameters used to achieve the best validation loss.\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model,train_iterator,optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'Pytorch Enc-Dec Model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "# Perplexity is the multiplicative inverse of the probability assigned to the test set by the language model, normalized by the number of words in the test set. If a language model can predict unseen words from the test set.\n",
        "#As a result, better language models will have lower perplexity values or higher probability values for a test set."
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 12m 6s\n",
            "\tTrain Loss: 5.055 | Train PPL: 156.858\n",
            "\t Val. Loss: 4.854 |  Val. PPL: 128.253\n",
            "Epoch: 02 | Time: 12m 5s\n",
            "\tTrain Loss: 4.594 | Train PPL:  98.851\n",
            "\t Val. Loss: 4.752 |  Val. PPL: 115.818\n",
            "Epoch: 03 | Time: 12m 4s\n",
            "\tTrain Loss: 4.238 | Train PPL:  69.272\n",
            "\t Val. Loss: 4.586 |  Val. PPL:  98.061\n",
            "Epoch: 04 | Time: 11m 59s\n",
            "\tTrain Loss: 4.028 | Train PPL:  56.158\n",
            "\t Val. Loss: 4.398 |  Val. PPL:  81.252\n",
            "Epoch: 05 | Time: 12m 4s\n",
            "\tTrain Loss: 3.831 | Train PPL:  46.114\n",
            "\t Val. Loss: 4.256 |  Val. PPL:  70.534\n",
            "Epoch: 06 | Time: 12m 4s\n",
            "\tTrain Loss: 3.653 | Train PPL:  38.585\n",
            "\t Val. Loss: 4.191 |  Val. PPL:  66.098\n",
            "Epoch: 07 | Time: 12m 1s\n",
            "\tTrain Loss: 3.480 | Train PPL:  32.455\n",
            "\t Val. Loss: 4.037 |  Val. PPL:  56.660\n",
            "Epoch: 08 | Time: 12m 1s\n",
            "\tTrain Loss: 3.323 | Train PPL:  27.757\n",
            "\t Val. Loss: 3.930 |  Val. PPL:  50.911\n",
            "Epoch: 09 | Time: 12m 4s\n",
            "\tTrain Loss: 3.179 | Train PPL:  24.030\n",
            "\t Val. Loss: 3.830 |  Val. PPL:  46.056\n",
            "Epoch: 10 | Time: 12m 4s\n",
            "\tTrain Loss: 3.035 | Train PPL:  20.793\n",
            "\t Val. Loss: 3.738 |  Val. PPL:  42.015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPH8-euy1aSB",
        "outputId": "64d8f0f8-13de-4bfc-9c23-2542d64fc206"
      },
      "source": [
        "#We'll load the parameters (state_dict) that gave our model the best validation loss and run it the model on the test set.\n",
        "model.load_state_dict(torch.load('Pytorch Enc-Dec Model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 3.732 | Test PPL:  41.757 |\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}